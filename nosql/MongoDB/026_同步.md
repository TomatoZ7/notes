# 同步

复制用于在多台服务器之间备份数据。`MongoDB` 的复制主要是使用操作日志 `oplog` 实现的。`oplog` 包含了主节点的每一次写操作。`oplog` 是主节点的 `local` 数据库中的一个**固定集合**。备份节点通过查询这个集合就可以知道需要进行复制的操作。

每个备份节点都维护着自己的 `oplog`，记录着每次从主节点复制数据的操作。这样，每个成员都可以作为同步源提供给其他成员使用。如图所示：

![image](https://github.com/TomatoZ7/notes-of-tz/blob/master/nosql/MongoDB/images/mongo_sync_1.jpg)

> 每个成员都维护着一份自己的 `oplog`，每个成员的 `oplog` 都应该跟主节点的 `oplog` 完全一致(可能会有一些延迟)。

备份节点从当前使用的同步源中获取需要执行的操作，然后在自己的数据集上执行这些操作，最后再将这些操作写进 `oplog`。如果遇到某个操作失败的情况(只有当同步源的数据损坏或者数据与主节点不一致时才可能发生)，那么备份节点就会停止从当前的同步源复制数据。

如果某个备份节点挂了，当它重启之后会自动从 `oplog` 中最后一个操作开始进行同步。由于复制操作的过程是先复制数据再写入 `oplog`，所以，备份节点可能会在已经同步过的数据上再次执行复制操作。`MongoDB` 在设计之初就考虑到了这种情况：将 `oplog` 中的同一个操作执行多次，与只执行一次的效果是一样的。

由于 `oplog` 大小固定，它只能保存特定数量的操作日志。通常，`oplog` 使用空间的增长速度与系统处理写请求的速率近乎相同：对单文档产生多少 KB 的写入请求，`oplog` 很可能也会写入相同 KB 的操作日志；如果单次写入请求影响到多个文档，如删除多文档或者多文档更新，那么 `oplog` 就会产生多条操作日志。

## 1 初始化同步

副本集中的成员启动之后，就会检查自身状态，确定是否可以从某个成员那里进行同步。如果不行的话，它会尝试从副本的另一个成员那里进行完整的数据复制。这个过程就是**初始化同步(initial syncing)**。

初始化同步包括几个步骤：

1. 选择一个成员作为同步源，在 `local.me` 中为自己创建一个标识符，删除所有已存在的数据库，以一个全新的状态开始进行同步：

```log
Mon Jan 30 11:09:18 [rsSync] replSet initial sync pending
Mon Jan 30 11:09:18 [rsSync] replSet syncing to: server-1:27017
Mon Jan 30 11:09:18 [rsSync] build index local.me { _id: 1 }
Mon Jan 30 11:09:18 [rsSync] build index done 0 records 0 secs
Mon Jan 30 11:09:18 [rsSync] replSet initial sync drop all databases
Mon Jan 30 11:09:18 [rsSync] dropAllDatabasesExceptLocal 1
```

在这个过程中，所有现有的数据都会被删除。应该只在不需要保留现有数据的情况下做初始化同步(或者将数据移到其他地方)，因为 `mongod` 会首先将现有数据删除。

2. 克隆，将同步源所有记录复制到本地。通常是最耗时的操作：

```log
Mon Jan 30 11:09:18 [rsSync] replSet initial sync clone all databases
Mon Jan 30 11:09:18 [rsSync] replSet initial sync cloning db: db1
Mon Jan 30 11:09:18 [fileAllocator] allocating new datafile /data/db/db1.ns,
    filling with zeroes...
```

3. 然后就进入 `oplog` 同步的第一步，克隆过程中的所有操作都会被记录到 `oplog` 中。如果有文档在克隆过程中被移动了，就可能会被遗漏，导致没有被克隆，对于这样的文档，可能需要重新进行克隆：

```log
Mon Jan 30 15:38:36 [rsSync] oplog sync 1 of 3
Mon Jan 30 15:38:36 [rsBackgroundSync] replSet syncing to: server-1:27017
Mon Jan 30 15:38:37 [rsSyncNotiǸer] replset setting oplog notiǸer to
    server-1:27017
Mon Jan 30 15:38:37 [repl writer worker 2] replication update of non-mod
    failed:
    { ts: Timestamp 1352215827000|17, h: -5618036261007523082, v: 2, op: "u",
        ns: "db1.someColl", o2: { _id: ObjectId('50992a2a7852201e750012b7') },
        o: { $set: { count.0: 2, count.1: 0 } } }
Mon Jan 30 15:38:37 [repl writer worker 2] replication info
    adding missing object
Mon Jan 30 15:38:37 [repl writer worker 2] replication missing object
    not found on source. presumably deleted later in oplog
```

上面是一个比较粗略的日志，显示了有文档需要重新克隆的情况。在克隆过程中也可能不会遗漏文档，这取决于流量等级和同步源上的操作类型。

4. 接下来是 `oplog` 同步过程的第二步，用于将第一个 `oplog` 同步中的操作记录下来。

```log
Mon Jan 30 15:39:41 [rsSync] oplog sync 2 of 3
```

这个过程比较简单，也没有太多输出。只有在没有东西需要克隆时，这个过程才会与第一个不同。

5. 到目前为止，本地的数据应该与主节点在某个时间点的数据集完全一致了，可以开始创建索引了。如果集合比较大或者要创建的索引比较多，这个过程会很耗时间：

```log
Mon Jan 30 15:39:43 [rsSync] replSet initial sync building indexes
Mon Jan 30 15:39:43 [rsSync] replSet initial sync cloning indexes for : db1
Mon Jan 30 15:39:43 [rsSync] build index db.allObjects { someColl: 1 }
Mon Jan 30 15:39:44 [rsSync] build index done. scanned 209844 total records.
    1.96 secs
```

6. 如果当前节点的数据仍然远远落后于同步源，那么 `oplog` 同步过程的最后一步就是将创建索引期间的所有操作全部同步过来：

```log
Tue Nov 6 16:05:59 [rsSync] oplog sync 3 of 3
```

7. 现在，当前成员已经完成了初始化同步，切换到普通同步状态，这时当前成员就可以成为备份节点了：

```log
Mon Jan 30 16:07:52 [rsSync] replSet initial sync done
Mon Jan 30 16:07:52 [rsSync] replSet syncing to: server-1:27017
Mon Jan 30 16:07:52 [rsSync] replSet SECONDARY
```

如果想跟踪初始化同步过程，最好的方式就是查看服务器日志。

克隆也可能损坏同步源的工作集(working set)。实际部署之后，可能会有一个频繁使用的数据子集常驻内存（因为操作系统要频繁访问这个子集）。**执行初始化同步时，会强制将当前成员的所有数据分页加载到内存中，这会导致需要频繁访问的数据不能常驻内存，所以会导致很多请求变慢**，因为原本只要在 RAM（内存）中就可以处理的数据要先从磁盘上加载。不过，对于比较小的数据集和性能比较好的服务器，初始化同步仍然是个简单易用的选项。

## 2 处理陈旧数据

如果备份节点远远落后于同步源当前的操作，那么这个备份节点就是**陈旧的(stale)**。陈旧的备份节点无法跟上同步源的节奏，因为同步源上的操作领先太多；如果要继续进行同步，备份节点需要跳过一些操作。

如果备份节点曾经停机过，写入量超过了自身处理能力，或者是有太多的读请求，这些情况都可能导致备份节点陈旧。

当一个备份节点陈旧之后，它会查看副本集中的其他成员，如果某个成员的 `oplog` 足够详尽，可以用于处理那些落下的操作，就从这个成员处进行同步。如果任何一个成员的 `oplog` 都没有参考价值，那么这个成员上的复制操作就会中止，这个成员需要重新进行完全同步（或者是从最近的备份中恢复）。

为了避免陈旧备份节点的出现，让主节点使用比较大的 `oplog` 保存足够多的操作日志是很重要的。大的 `oplog` 会占用更多的磁盘空间。通常来说，这是一个比较好的折中选择，因为磁盘会越来越便宜，而且实际中使用的 `oplog` 只有一小部分，因此 `oplog` 不占用太多 `RAM`。