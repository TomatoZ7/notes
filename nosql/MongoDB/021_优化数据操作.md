# 优化数据操作

如果要优化应用程序，首先必须知道对读写性能进行评估以便找到性能瓶颈。对读取操作的优化通常包括正确使用索引，以及尽可能将所需信息放在单个文档中返回。对写入操作的优化通常包括减少索引数量以及尽可能提高更新效率。

经常需要在读取和写入的效率之间权衡，权衡因素不仅仅只是其中一个的重要性，也包括两者的频繁程度的对比。如果你的应用程序写入操作更重要，但是执行一次写入需要进行 1000 次读取操作，那么还是应该首先优化读取速度。

## 1 优化文档增长

更新数据时，需要明确更新是否会导致文档体积增长，以及增长程度。

如果增长程度可预知，可以为文档预留足够的增长空间，这样可以避免文档移动，可以提高写入速度。

检查一下填充因子，如果它大约是 1.2 或者更大，可以考虑手动填充。如果要对文档进行手动填充，可以在创建文档时创建一个占空间比较大的字段，文件创建成功之后再将这个字段移除。这样就提前为文档分配了足够的空间供后续使用。

假设有一个餐馆评论的集合：

```js
{
    "_id" : ObjectId(),
    "restaurant" : "Le Cirque",
    "review" : "Hamburgers were overpriced."
    "userId" : ObjectId(),
    "tags" : []
}
```

`tags` 字段会随着用户不断添加标签而增长，应用程序可能经常需要执行这样的更新操作：

```js
>db.reviews.update({"_id": id},
... {"$push": {"tags": {"$each": ["French", "fine dining", "hambugers"]}}})
```

如果知道 `tags` 通常不会超过 100 字节，可以手动为文档流出足够的填充空间，在文档最后添加一个大字段：

```js
{
    "_id" : ObjectId(),
    "restaurant" : "Le Cirque",
    "review" : "Hamburgers were overpriced."
    "userId" : ObjectId(),
    "tags" : [],
    "garbage": "......................................................................"
}
```

可以在第一次插入时这么做，也可以在 `upsert` 时使用 `$setOnInsert` 创建这个字段。

更新文档时总是用 `$unset` 移除 `garbage` 字段，如果字段不存在，则 `$unset` 什么都不做：

```js
> db.reviews.update({"_id": id},
... {"$push": {"tags": {"$each": ["French", "fine dining", "hambugers"]}},
... "$unset": {"garbage": true}})
```

如果文档存在增长字段，应该将该字段放在最后的位置。这样可以稍微提高一点点性能，因为如果字段增长，`MongoDB` 不需要重写新增字段后面的内容。

## 2 删除旧数据

删除旧数据可以使用固定集合、TTL 集合或定期删除集合。

固定集合会对操作造成一些限制，而且在密集插入数据时数据的生命周期会变得很低。

TTL 集合对于写入量非常大的集合来说效率偏低，它通过遍历 TTL 索引来删除文档。

最后一种方法是使用多个集合，例如可以按月来使用集合(水平分表)，它比较麻烦的是需要使用动态的集合名，也要动态处理对多个数据库的查询。