# 建立副本集

使用 `MongoDB` 的复制功能可以将数据副本保存到多台服务器上，即使一台服务器出错，也可以保证应用程序正常运行和数据安全。

在 `MongoDB` 中，创建一个副本集之后就可以使用复制功能了。副本集是一组服务器，其中有一个**主服务器(primary)**，用于处理客户端请求；还有多个**备份服务器(secondary)**，用于保存主服务器的数据副本。如果主服务器崩溃了，备份服务器会自动将其中一个成员升级为新的主服务器。

接下来我们尝试在 `centos 7` 服务器上建立一个**包含三个成员的副本集**。

## 1 创建数据目录

`MongoDB` 启动时将使用一个数据目录存放所有的数据文件。我们将 3 个复制集节点创建各自的数据目录。

```shell
$ mkdir -p /data/db{1,2,3}
```

## 2 准备配置文件

复制集的每个 `mongod` 进程应该位于不同的服务器。我们现在在一台机器上运行 3 个进程，因此要为它们各自配置：

+ 不同的端口。将使用 28017/28018/28019

+ 不同的数据目录。将使用 `/data/db{1,2,3}`

+ 不同的日志文件路径。将使用 `/data/db{1,2,3}/mongod.log`

配置文件 `mongod.conf`：

```conf
systemLog:
    destination: file
    path: /data/db1/mongod.log    # log path
    logAppend: true
storage:
    dbPath: /data/db1    # data directory
net:
    bindIp: 0.0.0.0
    port: 28017
replication:
    replSetName: rs0
processManagement:
    fork: true  # 作为独立的后台进程
```

> 配置文件需遵循 `YAML` 格式，不可以使用 TAB 键，冒号 `:` 后面需跟上一个空格。

将三份配置文件放至三个 `db` 目录下，注意 `systemLog.path`、`storage.dbPath` 和 `net.port` 需要根据目录进行调整。

## 3 启动 mongod 进程

```shell
$ mongod -f /data/db1/mongod.conf
about to fork child process, waiting until server is ready for connections.
forked process: 20263
child process started successfully, parent exiting

$ mongod -f /data/db2/mongod.conf
$ mongod -f /data/db3/mongod.conf

# 查看 mongod 进程
$ ps -ef|grep mongo
root     17540     1  1 14:28 ?        00:00:23 mongod -f db1/mongod.conf
root     18364     1  1 14:35 ?        00:00:17 mongod -f db2/mongod.conf
root     20263     1  1 14:52 ?        00:00:04 mongod -f db3/mongod.conf
root     20829 26315  0 14:57 pts/0    00:00:00 grep --color=auto mongod
```

## 4 配置复制集

现在已经有 3 个 `mongod` 实例，但它们现在是各自独立的，互不相干的，所以我们现在需要将它们组合起来。

进入 `mongo`：

```shell
$ mongo --port 28017
```

### 4.1 方法 1

```shell
> rs.initiate()

rs0.SECONDARY>      # 回车，PRIMARY 和 SECONDARY 是当前成员的状态，rs0 是副本集的标识符
rs0.PRIMARY>

# 查看节点信息
rs0.PRIMARY> rs.status()

rs0.PRIMARY> rs.add("iZuf61wwjib0gi7cyckz02Z:28018")
rs0.PRIMARY> rs.add("iZuf61wwjib0gi7cyckz02Z:28019")
```

### 4.2 方法 2

```shell
$ rs.initiate({
    _id: "rs0",
    members: [{
        _id: 0,
        host: "localhost:28017"
    },{
        _id: 1,
        host: "localhost:28018"
    },{
        _id: 2,
        host: "localhost:28019"
    }]
})
```

> 注意如果需要远程连接，需配置成**域名:端口号**的形式，如 192.168.1.1:27017

# 5 验证

在节点上执行 `isMaster` 命令，可以看到副本集的状态：

```shell
rs0.PRIMARY> rs.isMaster()
{
	"topologyVersion" : {
		"processId" : ObjectId("61594d7aecd86a06f969a843"),
		"counter" : NumberLong(12)
	},
	"hosts" : [
		"iZuf61wwjib0gi7cyckz02Z:28017",
		"iZuf61wwjib0gi7cyckz02Z:28018",
		"iZuf61wwjib0gi7cyckz02Z:28019"
	],
	"passives" : [
		"hostname:28018",
		"hostname:28019"
	],
	"setName" : "rs0",
	"setVersion" : 7,
	"ismaster" : true,
	"secondary" : false,
	"primary" : "iZuf61wwjib0gi7cyckz02Z:28017",
	"me" : "iZuf61wwjib0gi7cyckz02Z:28017",
	"electionId" : ObjectId("7fffffff0000000000000001"),
	"lastWrite" : {
		"opTime" : {
			"ts" : Timestamp(1633261363, 1),
			"t" : NumberLong(1)
		},
		"lastWriteDate" : ISODate("2021-10-03T11:42:43Z"),
		"majorityOpTime" : {
			"ts" : Timestamp(1633261363, 1),
			"t" : NumberLong(1)
		},
		"majorityWriteDate" : ISODate("2021-10-03T11:42:43Z")
	},
	"maxBsonObjectSize" : 16777216,
	"maxMessageSizeBytes" : 48000000,
	"maxWriteBatchSize" : 100000,
	"localTime" : ISODate("2021-10-03T11:42:47.150Z"),
	"logicalSessionTimeoutMinutes" : 30,
	"connectionId" : 31,
	"minWireVersion" : 0,
	"maxWireVersion" : 13,
	"readOnly" : false,
	"ok" : 1,
	"$clusterTime" : {
		"clusterTime" : Timestamp(1633261363, 1),
		"signature" : {
			"hash" : BinData(0,"AAAAAAAAAAAAAAAAAAAAAAAAAAA="),
			"keyId" : NumberLong(0)
		}
	},
	"operationTime" : Timestamp(1633261363, 1)
}
```

`isMaster` 返回的字段有点多，其中 `{"ismaster" : true}` 指明了这是一个主节点，`hosts` 陈列了副本集的节点。

既然已经连接到主节点，试试插入 1000 个文档：

```shell
rs0.PRIMARY> for (i=0;i<1000;i++) { db.test.insert({count: i}) }
```

这时候另开一个 `shell` 并连接到其他节点：

```shell
$ mongo --port 28018
...

rs0:SECONDARY> db.test.count()
1000
```

> 备份节点可能会落后于主节点，没有最新写入的数据，所以备份节点在默认情况下会拒绝读取请求，以防止应用程序意外拿到过期的数据。因此，如果在备份节点上做查询，可能会得到一个错误提示，说当前节点不是主节点。
> 
> ```shell
> rs0:SECONDARY> db.test.count()
> {"code" : 13435, "errmsg" : "not master and slaveOk=false"}
> ```
>
> 如果希望备份节点读取数据，可以设置"从备份节点读取数据没有问题"标识：
>
> ```shell
> rs0:SECONDARY> rs.slaveOk()
> WARNING: slaveOk() is deprecated and may be removed in the next major release. Please use secondaryOk() instead.      # 5.0 版本弃用 slaveOk
> rs0:SECONDARY> rs.secondaryOk()
> ```

可以看到备份节点也存了 1000 份文档。

现在尝试在备份节点上写入：

```shell
rs0:SECONDARY> db.test.insert({ count: 1001 })
WriteCommandError({
	"ok" : 0,
	"errmsg" : "not master",
	"code" : 10107
})
```

可以看到，备份节点只能通过复制写入数据，不接受客户端的写入请求。

## 6 宕机测试

副本集拥有**自动故障转移(automatic failover)**。如果主节点挂了，其他有一个备份节点会自动选举为主节点。

现在关掉主节点：

```shell
rs0:PRIMARY> db.adminCommand({"shutdown": 1})
```

在备份节点执行 `isMaster`：

```shell
rs0:SECONDARY> rs.isMaster()
{
	"topologyVersion" : {
		"processId" : ObjectId("61594f1c70cc3bfa09ab5f2a"),
		"counter" : NumberLong(9)
	},
	"hosts" : [
		"iZuf61wwjib0gi7cyckz02Z:28017",
		"iZuf61wwjib0gi7cyckz02Z:28018",
		"iZuf61wwjib0gi7cyckz02Z:28019"
	],
	"passives" : [
		"hostname:28018",
		"hostname:28019"
	],
	"setName" : "rs0",
	"setVersion" : 7,
	"ismaster" : true,
	"secondary" : false,
	"primary" : "iZuf61wwjib0gi7cyckz02Z:28018",
	"me" : "iZuf61wwjib0gi7cyckz02Z:28018",
	"electionId" : ObjectId("7fffffff0000000000000002"),
	"lastWrite" : {
		"opTime" : {
			"ts" : Timestamp(1633269247, 1),
			"t" : NumberLong(2)
		},
		"lastWriteDate" : ISODate("2021-10-03T13:54:07Z"),
		"majorityOpTime" : {
			"ts" : Timestamp(1633269247, 1),
			"t" : NumberLong(2)
		},
		"majorityWriteDate" : ISODate("2021-10-03T13:54:07Z")
	},
	"maxBsonObjectSize" : 16777216,
	"maxMessageSizeBytes" : 48000000,
	"maxWriteBatchSize" : 100000,
	"localTime" : ISODate("2021-10-03T13:54:17.069Z"),
	"logicalSessionTimeoutMinutes" : 30,
	"connectionId" : 37,
	"minWireVersion" : 0,
	"maxWireVersion" : 13,
	"readOnly" : false,
	"ok" : 1,
	"$clusterTime" : {
		"clusterTime" : Timestamp(1633269247, 1),
		"signature" : {
			"hash" : BinData(0,"AAAAAAAAAAAAAAAAAAAAAAAAAAA="),
			"keyId" : NumberLong(0)
		}
	},
	"operationTime" : Timestamp(1633269247, 1)
}
```

新的主节点也可以是其他服务器。第一个检测到主节点挂了的备份节点会成为新的主节点。现在可以向新的主节点发送写入请求了。