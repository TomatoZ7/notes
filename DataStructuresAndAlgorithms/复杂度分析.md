# 复杂度分析

时间、空间复杂度能够帮助我们衡量算法代码的执行效率。

## 1 复杂度分析的必要性

通过把代码执行一遍，统计、监控得到算法的执行时间和占用的内存大小是非常主观的：

1. 测试环境中硬件的不同会对测试结果有很大的影响。

2. 测试结果受数据规模的大小影响。

如同一个排序算法不同数据的有序度、大小都会影响到最终结果。

**所以，我们需要一个不用具体的数据来测试，就可以粗略地股计算法的执行效率的方法。 ---- 复杂度分析**

## 2 大 O 复杂度表示法

算法的执行效率，粗略地讲，就是算法代码执行的时间。

我们尝试估算下面这段代码的执行时间：

```java
int cal(int n) {
    int sum = 0;
    int i = 1;
    for (; i <= n; ++i) {
        sum = sum + 1;
    }
    return sum;
}
```

从 `CPU` 的角度来看，每一行代码都执行着类似操作：**读数据-运算-写数据**。尽管每行代码对应的 `CPU` 执行的个数、时间都不一样。但是，我们只是粗略的估计，姑且认为每行代码的执行时间都一样，为 `unit_time`。

在这个假设的基础上，第 2 - 3 行代码分别需要 1 个 `unit_time` 的执行时间，第 4 - 5 行都运行 `n` 次，所以需要 `2n * unit_time` 的执行时间，所以这段代码的执行时间就是 `(2n + 2) * unit_time`。可以看出，**所有代码的执行时间 `T(n)` 与每行代码的执行次数成正比。**

我们再看这段代码：

```java
int cal(int n) {
    int sum = 0;
    int i = 1;
    int j = 1;
    for (; i <= n; ++j) {
        j = 1;
        for (; j <= n; ++j) {
            sum = sum + i * j;
        }
    }
}
```

遵循上述估算方式，第 2 - 4 行各需 1 个 `unit_time` 的执行时间，第 5、6 行循环运行 `n` 次，需要 `2n * unit_time` 执行时间，第 7、8 行循环运行 `n^2` 次，需要 `2n^2 * unit_time` 的执行时间。所以这段代码总执行时间为：`T(n) = (2n^2 + 2n + 3) * unit_time`。

但是通过这两段代码执行时间的推导过程，我们可以得出一个很重要的规律：**所有代码的执行时间 `T(n)` 与每行代码的执行次数 `f(n)` 成正比。**总结成公式：

```math
T(n) = O( f(n) )
```

其中 `T(n)` 表示代码执行时间；`n` 表示数据规模的大小；`f(n)` 表示每行代码执行的次数总和。因为这是一个公式，所以用 `f(n)` 来表示。公式中的 `O`，表示代码的执行时间 `T(n)` 与 `f(n)` 表示式成正比。

所以，第一个例子中的 `T(n) = O(2n + 2)`，第二个例子中的 `T(n) = O(2n^2 + 2n + 3)。这就是**大 O 时间复杂度表示法**。大 O 时间复杂度并不具体表示代码的真正执行时间，而是表示**代码执行时间随数据规模增长的变化趋势**，所以，也叫做**渐进时间复杂度**。

当 `n` 达到 10000 乃至更大时，公式中的低阶、常量、系数并不左右增长趋势，均可以忽略。我们只记录一个最大量级即可。如果用大 O 表示法表示刚讲的那两段代码的时间复杂度，就可以记为：`T(n) = O(n)`、`T(n) = O(n^2)`。

## 3 时间复杂度分析

下面介绍 3 个比较实用的方法帮助我们分析时间复杂度。

### 3.1 只关注循环执行次数最多的一段代码

循环执行次数最多的那段代码，它的执行次数的 n 的两集，就是整段要分析代码的时间复杂度。

以上述代码为例：

```java
int cal(int n) {
    int sum = 0;
    int i = 1;
    for (; i <= n; ++i) {
        sum = sum + i;
    }
    return sum;
}
```

第 2、3 行均是常量级执行时间，与 `n` 的大小无关，对复杂度没有影响。循环执行次数最多的是 4、5 行代码，所以这块代码需要重点分析。这两行代码被执行了 `n` 次，所以总的时间复杂度就是 `O(n)`。

### 3.2 加法法则：总复杂度等于量级最大的那段代码的复杂度

我们根据下面这段代码来分析：

```java
int cal(int n) {
    int sum_1 = 0;
    int p = 1;
    for (; p < 100; ++p) {
        sum_1 = sum_1 + p;
    }

    int sum_2 = 0;
    int q = 1;
    for (; q < n; ++q) {
        sun_2 = sum_2 + q;
    }

    int sum_3 = 0;
    int i = 1;
    int j = 1;
    for (; i <= n; ++i) {
        j = 1;
        for (; j <= n; ++j) {
            sum_3 = sum_3 + i * j;
        }
    }

    return sum_1 + sum_2 + sum_3;
}
```

这段代码分为 3 部分，分别是求 `sum_1`、`sum_2` 和 `sum_3`。我们可以分别分析每一小段的时间复杂度，然后将它们相加取量级最大的作为整段代码的复杂度。

第一段代码循环执行了 100 次，是一个常量的执行时间，跟 `n` 的规模无关。

> 即使是它执行了 10000 次、100000 次，只要是一个已知的数，跟 `n` 无关，照样也是常量级的执行时间。当 `n` 无限大时，也可以忽略。尽管对代码的执行时间会有很大影响，但是回到时间复杂度的概念来说，它表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，我们都可以忽略掉。因为它本身对增长趋势并没有影响。

第二、三段代码分别循环执行了 `n`、`n^2` 次。

综合三段代码的时间复杂度，我们取其中最大的量级，也就是 `O(n^2)`。也就是说，**总的时间复杂度等于量级最大的那段代码的时间复杂度。**抽象成公式就是：

如果 `T1(n) = O(f(n))`，`T2(n) = O(g(n))`，那么 `T(n) = T1(n) + T2(n) = max(O(f(n)), O(g(n))) = O(max(f(n), g(n)))`。

### 3.3 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

如果 `T1(n) = O(f(n))`，`T2(n) = O(g(n))`，那么 `T(n) = T1(n) * T2(n) = O(f(n)) * O(g(n)) = O(f(n) * g(n))`。

也就是说，如果 `T1(n) = O(n)`，`T2(n) = O(n^2)`，则 `T1(n) * T2(n) = O(n^3)`。

在代码中我们可以把乘法法则看成是**嵌套循环**，举个例子：

```java
int cal(int n) {
    int ret = 0;
    int i = 1;
    for (; i < n; ++i) {
        ret = ret + f(i);
    }
}

int f(int n) {
    int sum = 0;
    int i = 1;
    for (; i < n; ++i) {
        sum = sum + i;
    }
    return sum;
}
```

我们单独看 `cal()` 函数，假设 `f()` 只是一个普通的操作，那么第 4 - 6 行的时间复杂度就是 `T1(n) = O(n)`。而 `f()` 并不是一个普通的操作，它执行的时间复杂度是 `T2(n) = O(n)`，所以，整个 `cal()` 函数的时间复杂度就是 `T(n) = T1(n) + T2(n) = O(n*n) = O(n^2)`。